### Hi there üëã
I'm MJ and I'm a Technical Lead at Waters!

In my day job I write .Net micro-services and use AWS cloud technologies but in my spare time I also develop mobile applications using Xamain Forms.
I also have experience developing IoT solutions ad I'm currently playing with Wilderness Labs Meadow boards.

### üìô Blog Posts
<!--START_SECTION:feed-->
#### [Exploring Ubuntu Desktop on the Raspberry PI](https:&#x2F;&#x2F;blog.mjjames.co.uk&#x2F;2020&#x2F;10&#x2F;exploring-ubuntu-desktop-on-raspberry-pi.html) 
*With the release of Ubuntu Desktop 20.10 being available for the Raspberry PI this week I thought I&#39;d take it out for a spin on one of the Raspberry PI 4&#39;s I have lying around. Now, officially you need to use a 4GB or 8GB device, however both of my spare ones only have 2GB so thought I&#39;d try anyway and if things go well look at treating myself to a new shiny 8GB one.Note: most of this post was written on the 25th however after a mishap (I knocked the PI off my desk and broke the SD Card slot üòíI had to wait until the 31st to complete the .NET 5 test instead running the PI 4 via an old USB SSD)Initial InstallFirst off Installing Ubuntu Desktop 20.10 is nice and easy, you can get the image and apply it to an SD Card or for a nice step through wizard the Raspberry PI installer is the way to go. It&#39;s a nice four step process, choose Ubuntu and then 20.10 Ubuntu Desktop, choose the destination device and click write. It takes a while to write and verify but once complete you can eject your SD Card and slot it into your PI 4, power up and off you go!.Disk SpeedA quick aside, I&#39;ve ended up doing this twice over, usually I use a Samsung Evo 32GB SD Card as I know them to be quick and reliable but initially I thought one of my USB 3 sticks would have performed better so chose to use that. This was a mistake :( If you have multiple USB sticks or even SD Cards I recommend running a benchmark tool against each of them to find the best one to use. My USB stick experience wasn&#39;t great and kept having random pauses &#x2F; stutters. After benchmarking I found my USB stick was not up to any sort of standard.&amp;nbsp; 65MB&#x2F;s Read... but bare 5.4MB&#x2F;s write :( I also tested a few of my SD Cards and decided to use one of my Kingston gold cards as although it scored 10MB&#x2F;s lower in sequential reads its write speed was much higher. Now the 4K performance is often a true tail of random reads and writes for a disk but the test was taking too long so I opted to just base my decision on the sequential tests.First BootThe first time I tried to boot just using my Raspberry PI Touchscreen, I can confirm that although it works you will struggle to setup and configure the device. Like most desktop OS&#39; they expect a 1024x768 resolution minimum and without this menu&#39;s or buttons get blocked. This was the case for me so I had to switch to a 1080p monitor, not a hardship and actually better for testing the OS anyway but it&#39;s worth noting, particulary if you are thinking about Ubuntu Desktop for any small TouchScreen UI&#39;s. I will revisit using the touchscreen as I&#39;m sure once configured running a browser or application in kiosk mode would be more than possible.The initial boot does take a few minutes as the filesystem is resized, but once done you are presented with a short wizard to setup your keyboard, wi-fi, time zone, account and device name.&amp;nbsp;Once configured theres an additional install process that takes around 10 minutes and a few reboots will occur. The OS is then ready for use.What can it run?Ubuntu Desktop comes with a few common applications, Firefox for Web Browsing, Libre Office as well as a few others. Although I&#39;m looking to see if using Ubuntu Desktop 20.10 on a PI 4 would be suitable for my 2 boys (age 9 &amp; 5), web browsing and word processing,&amp;nbsp; I couldn&#39;t help but wonder how Visual Studio Code would run, given its now available for arm64 :D&amp;nbsp;Remote AccessI&#39;ll be honest I wanted to finish configuring and testing from my main laptop so my first thing to setup was remote access. First up SSH, I kept with openssh-server. I then tried to using the built in screen sharing &#x2F; VNC, you enable it via settings. However, after enabling it I couldn&#39;t get RealVNC, TightVNC, UltraVNC to connect, they all reported &quot;security setting&quot; issues.&amp;nbsp;I could have dug into this but remote access isn&#39;t my current concern so I decided to switch to RDP instead (which is how I&#39;ve always connected to Ubuntu running via a Hyper-V VM before I switched to using WSL). To install this open your terminal (or connect via SSH) and install xrdp and enable it.&amp;nbsp;sudo apt install xrdpsudo systemctl enable xrdpI could then use Remote Desktop Client to connect to the desktop. It&#39;s worth noting however that you can only connect if no other user is logged in.&amp;nbsp; I also found I had some weirdness with the gnome desktop but things functioned enough.Visual Studio CodeOK, with remote access sorted I wanted to get Visual Studio Code installed. I went to&amp;nbsp;https:&#x2F;&#x2F;code.visualstudio.com&#x2F;Download and chose the arm64 .deb.With the deb file downloaded you can then open this via the Ubuntu Software installer by right clicking and choosing &quot;Open with Software Install&quot;,&amp;nbsp;or you can use the terminal and use apt install.mj@mjpi002:~&#x2F;Downloads$ sudo apt install .&#x2F;code_1.50.1-1602600638_arm64.debI could then launch VS Code from the launcher.It launched quickly and felt responsive. I even used the terminal within it, again snappy and responsive, I installed git again with no problems.Running .NET 5With VSCode running, lets push the boat further and try running .NET 5... Just like installing VSCode this is straight forward, go to&amp;nbsp;go to the .NET 5.0 download page&amp;nbsp;and choose arm64Follow the instructions and you should find you then have .NET 5 running....A good experiment is to use one of the dotnet templates, rather than a low spec console application I decided to push things and try the blazor server template.It literally took seconds, notice how tight I am here on memory, this now begins to really affect things.... however dotnet run gave me after a few minutes....Once running it was very quick and responsive and I could happily open the source in VSCode and make changes and run them.dotnet build with no changes, as expected no real time&amp;nbsp;then a build following a clean, not horrendous, but the limitations of the hardware are beginning to show.Next up, let&#39;s try one of my solutions from work, its not a full app but a set of library packages built into NuGet packagesOuch. Hitting CPU and memory limits but it did complete.Code editor looking great though and responsive. No omnisharp however üôàOne day maybe...The 9 Year Old TestAfter proving all of the dev capabilities I thought why not let my 9 year old have ago... I had pinched his mechanical keyboard and mouse after all... So turns out his first test was &quot;crazy games&quot; and the CPU got slammed.But apparently it&#39;s faster than his 7 year old laptop so maybe he&#39;ll keep it.Overall ThoughtsI can see a lot of potential with Ubuntu Desktop on the PI 4, it wasn&#39;t super fast and slick but it was better than expected. It definitely got better once I swapped from an SD Card to an SSD over a USB interface.&amp;nbsp;The installation was smooth and fairly quick, getting Visual Studio Code and .NET 5 installed was great and they performed better than expected.I highly suspect by me running this on a 2GB PI 4 and not a 4GB or 8GB some of the perf issues and stalls I experienced were caused by this. My memory was always running high and I occasionally saw things spooling out to the swap file and at one point even reached it&#39;s 1GB default limit.&amp;nbsp;So I can confirm as expected only try this on a 4GB+ version of a PI 4üòÅ*
#### [Experiments with WSL2... Yes you can use VSCode but could you run...](https:&#x2F;&#x2F;blog.mjjames.co.uk&#x2F;2020&#x2F;06&#x2F;experiments-with-wsl2-yes-you-can-use.html) 
*I&#39;m a massive fan of WSL and now WSL2 is finally here (I&#39;ve been using it during preview since day 1 but my work machine sadly couldn&#39;t run it until now...). With the Docker Desktop integration and some awesome I&#x2F;O and performance metrics it really is good. This great article by Phoronix really shows how near native it is.I often checkout some of my newer work code out in Ubuntu and then use VSCode for doing my work where appropriate however C# in VSCode is OK but it&#39;s not *great* VS2019 is still a better experience on the whole. About 2 months ago I tried JetBrains Rider 2020 out and although I liked it I couldn&#39;t quite justify using it on Windows instead of VS2019 which my work MSDN provides, however tonight I had a thought... Rider is cross platform, windows, macos and linux... could I get Rider running via WSL2 would it be awesome or horrible.... Let&#39;s find out....22:00 Time to Start! First I go to JetBrains website and go grab the download link for the Linux version: https:&#x2F;&#x2F;www.jetbrains.com&#x2F;rider&#x2F;download&#x2F;#section&#x3D;linux when you click the download you will get the tar.gz file and will be prompted where to save it. You could download to your Windows Downloads file and then copy to WSL but I chose to cancel it and instead copied the direct link.With this link I crack open WSL and wget the file. It&#39;s worth providing an output file path or trimming the analytics tracking code as otherwise it downloads with a naff filename. wget https:&#x2F;&#x2F;download.jetbrains.com&#x2F;rider&#x2F;JetBrains.Rider-2020.1.3.tar.gzOnce downloaded extract it:&amp;nbsp;tar xvf JetBrains.Rider-2020.1.3.tar.gz, this will take a few mins... Once extracted you can cd into the directory, theres a handy readme explaining how to run Rider on Linux but effectively cd to bin and run .&#x2F;rider.sh . Now this will fail within WSL as you won&#39;t have a display yet.22:20But never fear, clever people have made it possible to run a X11 server via Windows and have WSL connect to it ... I know amazing! Open Windows Store and search for X11 there are a few available but I use X410, it costs but when its on offer its not too expensive. I&#39;m going to assume you are using X410 but others will work fine. With X410 installed run it and you&#39;ll see the X icon saying its running. Originally on WSL1 this just worked but due to changes in WSL2 using Hyper-V you need to follow the instructions on the X410 website. Allow Public Access is a bit weird, hopefully WSL2 in the future will fix this (I know its on the radar).Then run .&#x2F;rider.sh again and you should see something different this time :DYou then need to activate a licence, you can get a 30 day trial licence if you want to experiment.22:40  Everything is licenced and running :) So I hear you say.. yeah yeah is this really Rider within WSL... Open a solution ;) Rather than mess around with a massive solution I thought for this post I&#39;ll create the inevitable Hello World Project.&amp;nbsp;I create it fine as I&#39;d expect but... I try to NuGet Restore and Run and hit an issue :( Drat.  I decide to open the log and it&#39;s not super helpful, I then think to open the packages folder and get an error message I can do something about...&amp;nbsp;I create the missing folder and try again... same error :( 23:10  Hmm, bit stumped on this so will need to do some googling but let&#39;s try something different. Let&#39;s use dotnet cli to do the NuGet restore and then compile and run my app. NuGet restore worked fine :) Now lets run the app.... Hoorah!23:20 So it appears to work fine in a basic sense, enough to try out on a real project and then find what works and what doesn&#39;t :D&amp;nbsp;Things I have noticed though:       I have found the DPI scaling on W410 to not be great. High Quality is pretty good but not great, I can run without it and thing&#39;s aren&#39;t too bad.     Rider&#39;s password manager won&#39;t work with the native keychain. In settings you can set to not store any or use KeePass. I&#39;m currently using KeePass.    23:30That&#39;s enough for tonight but it&#39;s worth trying out more for sure. I need to find what the root cause of the NuGet restore issue is as having to use the CLI does distract. Additionally although you can search NuGet for packages you can&#39;t install any which is a pain.&amp;nbsp;I didn&#39;t even expect to get this far at the start so the fact I have something working is amazing and something more people should look at doing, who knows maybe this could be a really productive way of developing .NET within a Linux not just using Docker or VSCode.I will update this post as and when I get NuGet working and updated when I have tested this further.*
#### [Running a TFS Build Agent on your Raspberry PI &#x2F; ARM based device](https:&#x2F;&#x2F;blog.mjjames.co.uk&#x2F;2019&#x2F;07&#x2F;running-tfs-build-agent-on-your.html) 
*As I&#39;ve mentioned a few times recently I&#39;ve been pushing our use of ARM based devices at work for a while now. What started on Raspberry PI 2&#39;s &amp;&amp;nbsp; 3&#39;s as prototypes and early builds has developed into something much bigger. Which is great, however the way we&#39;ve been writing and building code has got stuck in a bad process. For all of our .Net Core code we have a full CI pipeline which produces appropriate outputs for deploy to our devcies in an automated way. However in some of our more recent work we&#39;ve needed to start compiling third party dependencies for our ARM based boards and even some C++ components.It&#39;s always been on the &quot;Todo:&quot; list to ensure these dependencies and components got into our CI pipeline but with using various contractors and being &quot;busy&quot; things have gone too long with &quot;works on my machine&quot; builds and various network shares containing &quot;OpenCV NEON optimised&quot; and other such dependencies.With the release of the Raspberry PI 4 last week and me ordering a 6 pack of these I decided it was time to not only compare how long things took to build on a PI 4 vs PI 3 &#x2F; Compute Module but also to use 2 of my 6 as &quot;ARM Build Agents&quot; and add them to our TFS 2018 setup.Below is a rough log of what I did, what I had to find out and hopefully how I got everything working :)First StepsThe first steps were simply getting the latest version of Raspbian and installing this on my new Raspberry PI 4&#39;s and my bespoke Compute Module 3 setup. For both devices I wanted a very &quot;lite&quot; setup so chose the latest Raspbian Lite which is based on Debian Buster (at the time of writing this Buster isn&#39;t officially released but it&#39;s super close), it has no desktop which is perfect for our Build Agent. No use wasting resources on a full Desktop Experience, SSH is all you need ;).&amp;nbsp;For the PI 4 I simply downloaded Raspbian and wrote the image to an SD Card but for my CM3 setup I wrote it directly to our eMMC module. For writing the image to the SD Card and our eMMC module I used ImageUSB as I find this to be a very good Windows Imaging solution, it looks dated but works really well and can do multiple devices at the same time. I use it to make images as much as I use it to deploy images.With the images deployed I booted up both devices, changed the default password, enabled SSH via the raspi-config utility and then once all rebooted ensure all of the packages were fully up to date.sudo apt updatesudo apt upgradeYes I am also doing all of this from Windows TerminalInstalling the TFS&#x2F;Azure DevOps Build AgentWith the device up to date it was time to install the TFS &#x2F; Azure DevOps Build Agent to the device. To deploy agents previously I&#39;ve just navigated to the Agent Pools area within the TFS portal however dependant on your TFS version &#x2F; if you are using Azure DevOps the URL can change. I highly recommend reading the docs for deploying a Linux Agent as it covers most things you need to know including authentication etc. However there was one thing I found a pain, it indicates the following:On the Get agent dialog box, click Linux.On the left pane, select the specific flavor. We offer x64 or ARM for most Linux distributions. We also offer a specific build for Red Hat Enterprise Linux 6.On the right pane, click the Download button.But, this always gave me the x64 Linux agent, I needed a URL for the ARM build for my device. My first attempt to solve this was to swap the x64 part of the link to armFrom:&amp;nbsp;https:&#x2F;&#x2F;vstsagentpackage.azureedge.net&#x2F;agent&#x2F;2.131.0&#x2F;vsts-agent-linux-x64-2.131.0.tar.gzTo: From:&amp;nbsp;https:&#x2F;&#x2F;vstsagentpackage.azureedge.net&#x2F;agent&#x2F;2.131.0&#x2F;vsts-agent-linux-arm-2.131.0.tar.gzBut this didn&#39;t work. :(Next I decided to go find the source of the agent on GitHub&amp;nbsp;this quite happily shows ARM Linux builds as well as install information.However all of the links go back to the same documentation with no actual links! At this point I almost decided to give up but the Azure Pipeline badges made me thing it has to be outputting them somewhere.... so I went digging :)Hurrah Releases!Look at that lovely file name with the build numberThis then meant I could do some substution and get an agent url of https:&#x2F;&#x2F;vstsagentpackage.azureedge.net&#x2F;agent&#x2F;2.154.0&#x2F;vsts-agent-linux-arm-2.154.0.tar.gz&amp;nbsp;Hurrah a working link. Now it&#39;s time to get it onto the devices.&amp;nbsp; You could download the package and SCP it across to the device but that feels like hassle. Instead I just used wget to download the package straight onto the device:wget https:&#x2F;&#x2F;vstsagentpackage.azureedge.net&#x2F;agent&#x2F;2.154.0&#x2F;vsts-agent-linux-arm-2.154.0.tar.gzWith this done I could follow the previous instructions but updated the version numbers:mkdir agent &amp;&amp; cd agenttar zxvf ~&#x2F;vsts-agent-linux-arm-2.154.0.tar.gzNow with this extracted I came to configure the agent with&amp;nbsp;.&#x2F;config.sh but found I was missing dependencies so followed the instructions and ran&amp;nbsp;sudo .&#x2F;bin&#x2F;installdependencies.shThis however currently errors on Buster due to missing dependencies , I came to find all the dependency updates and potentially submit a PR back to update the script but fortunately found ItalyPaleAle had already done this&amp;nbsp;so I just used wget to get the script directly and then run it. (Although I&#39;ve provided the commands below it&#39;s worth double checking the script before executing it as sudo to ensure it&#39;s not got any nasties in it :) )wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;microsoft&#x2F;azure-pipelines-agent&#x2F;bb3afca3a2b1032842073c80bb5f1cfd0516665f&#x2F;src&#x2F;Misc&#x2F;layoutbin&#x2F;installdependencies.shchmod +x installdependencies.sh &amp;&amp; sudo .&#x2F;installdependencies.shWith the dependencies installed i then reran .&#x2F;config.sh but again hit another error:.&#x2F;bin&#x2F;System.Net.Http.Native.so: &#x2F;usr&#x2F;lib&#x2F;arm-linux-gnueabihf&#x2F;libcurl.so.4: version &#x60;CURL_OPENSSL_3&#39; not found (required by .&#x2F;bin&#x2F;System.Net.Http.Native.so)Dependencies is missing for Dotnet Core 2.1Fail So, more Googling led me to find this GitHub issue for .Net Core&amp;nbsp;in which our friend ItalyPaleAle has also added a comment!So what next....Essentially, I went back to the previous version of Raspbian and gave up on supporting the Raspberry PI 4 at this time. Back on Rasbian Stretch we can successfully run config.sh.As part of the config you have to accept a End User licence agreement and then provide the TFS&#x2F;Azure DevOps url. Use the documentation on how to find the URL to use.&amp;nbsp; You then have to provide a Personal Access Token for the Build Agent to use to authenticate with your TFS&#x2F;Azure Dev Ops environment, follow the documentation on how to set this up and with what permissions.Here I hit another issue, I kept getting Resource not available errors whilst trying to authenticateBit of googling led me to this GitHub issue, Annoyingly it indicates a workaround not a fix. I had to temporarily disable HTTP basic auth within IIS, get the agent registered and then re-enable it as we use basic auth as a workaround for our NuGet issue ;(With this all finally configured our agent appears within TFSI then configured to run the agent as a systemd service so it auto starts etcWith this complete the agent is ready waiting for jobs.Additional Dependencies &#x2F; ConfigurationAs things stand the Agent is running but it&#39;s not particularly useful. It doesn&#39;t have git or any of our build dependencies. The next step was to install these dependencies.sudo apt install gitetcand then finally....Oh yeah! Running builds on the pi&#39;sSuccess :)I will update this post once the Buster is fully supported and ensure there&#39;s no other steps required. You can see it wasn&#39;t a straight forward setup as I hoped and this process definitely made me appreciate the potential value of using Microsoft Hosted Agents&amp;nbsp;but overall everything is running and hopefully giving the team some value and reliable builds :)Hope this helps.&amp;nbsp;*
#### [DotNet CLI , private NuGet feeds and Linux...](https:&#x2F;&#x2F;blog.mjjames.co.uk&#x2F;2019&#x2F;06&#x2F;dotnet-cli-private-nuget-feeds-and-linux.html) 
*Today I hit an issue whilst trying to run dotnet run for some of our benchmarkdotnet tests which I like to run all new hardware I try out. My pair of Raspberry PI 4&#39;s arrived and I wanted to compare the performance of our Fingerprint capture code. I&#39;ve hit the issue before and last time I figured it out I swore I&#39;d blog and write it up as I knew I would forget!My benchmark project is a straight forward BenchmarkDotNet project however it consumers NuGet packages from both nuget.org as well as our private NuGet repository which requires authentication. For all of our windows machines this works without an issue for machines on the domain they authenticate seemlessly however when using Linux devices this is a different issue :(Instead on Linux devices we always get:&#x2F;home&#x2F;pi&#x2F;dotnet&#x2F;sdk&#x2F;2.2.300&#x2F;NuGet.targets(121,5): error :&amp;nbsp; &amp;nbsp;GSSAPI operation failed with error - An invalid status code was supplied (SPNEGO cannot find mechanisms to negotiate).This essentially means it was unable to find a way to negotiate from kerberos to ntlm authentication with the server, as discussed in this issue on GitHub. It&#39;s worth reading the issue as it looks like this is fixed for .Net Core 3.0 which is expected to be released in September 2019.Until .Net Core 3.0 is here I need a workaround, I know you can provide credentials for a NuGet provider via a nuget.config file in your repository, this might be the answer. Within the nuget.config you can add your package source and then within a packageSourceCredentials&amp;nbsp; element provide the auth details.For example:&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;utf-8&quot;?&gt;&lt;configuration&gt; &lt;packageSources&gt;  &lt;add key&#x3D;&quot;nuget.org&quot; value&#x3D;&quot;https:&#x2F;&#x2F;api.nuget.org&#x2F;v3&#x2F;index.json&quot; &#x2F;&gt;  &lt;add key&#x3D;&quot;private-nuget&quot; value&#x3D;&quot;https:&#x2F;&#x2F;private-tfs.example.com&#x2F;Team&#x2F;_packaging&#x2F;Company&#x2F;nuget&#x2F;v3&#x2F;index.json&quot; &#x2F;&gt; &lt;&#x2F;packageSources&gt; &lt;activePackageSource&gt;  &lt;add key&#x3D;&quot;All&quot; value&#x3D;&quot;(Aggregate source)&quot; &#x2F;&gt; &lt;&#x2F;activePackageSource&gt; &lt;packageSourceCredentials&gt;  &lt;private-nuget&gt;   &lt;add key&#x3D;&quot;Username&quot; value&#x3D;&quot;NugetReader&quot; &#x2F;&gt;   &lt;add key&#x3D;&quot;ClearTextPassword&quot; value&#x3D;&quot;i&#39;m a secret!&quot; &#x2F;&gt;  &lt;&#x2F;private-nuget&gt; &lt;&#x2F;packageSourceCredentials&gt;&lt;&#x2F;configuration&gt;Note that the key you provide for the package source you then use as the element name within the packageSourceCredentials Element. I used &lt;add key&#x3D;&quot;private-nuget&quot; &#x2F;&gt; so my element name was then &lt;private-nuget&gt;When on Windows and using nuget.exe you can provide the username and password for the package source as command line arguments and the password will be stored in the nuget.config in an encrypted form. However currently on Linux this isn&#39;t supported. Instead you have to use ClearTextPassword, bare this in mind and ensure you use a unique username and password for your package source user account which only has limited access to your repository.The above config however although worked fine on our Windows machines I still ran into a new error on Linux.&#x2F;home&#x2F;pi&#x2F;dotnet&#x2F;sdk&#x2F;2.2.300&#x2F;NuGet.targets(121,5): error :&amp;nbsp; &amp;nbsp;GSSAPI operation failed with error - An invalid status code was supplied (Configuration file does not specify default realm).Essentially now this still boils down to the negotiation but this time whether this username is for the server or the domain etc. This is where I couldn&#39;t remember what I had done last time to make this work. I knew it was something to do with changing the authentication type to basic. After some searching I eventually found how you do this. As part of your packageSourceCredentials you specify the valid authentication methods, in this case I only want basic. &lt;packageSourceCredentials&gt;  &lt;private-nuget&gt;   &lt;add key&#x3D;&quot;Username&quot; value&#x3D;&quot;NugetReader&quot; &#x2F;&gt;   &lt;add key&#x3D;&quot;ClearTextPassword&quot; value&#x3D;&quot;i&#39;m a secret!&quot; &#x2F;&gt;   &lt;add key&#x3D;&quot;ValidAuthenticationTypes&quot; value&#x3D;&quot;basic&quot; &#x2F;&gt;  &lt;&#x2F;private-nuget&gt; &lt;&#x2F;packageSourceCredentials&gt;With this all set everything restored and built fine! Hurrah!Now this works but is there a better way to do this? Essentially yes! You can use the&amp;nbsp;Azure Artifacts Credential Provider this works not only for Azure DevOps but also locally hosted TFS. Simply follow the instructions provided in the readme&amp;nbsp;and then do you dotnet restore but ensure you provide the --interactive argument. You will then be asked for your credentials which are then used to generate a session token. The readme also contains how you can use this for build servers etc. However, it does appear that this provider does seem to have issues dependant on your version of .Net Core&amp;nbsp;however I&#39;m hoping they are resolved soon.If you do run into any issues as mentioned on that issues list you can at least use the nuget.config approach until it is fixed.Hope this helps.*
#### [Can you use BuildRoot with Windows Subsystem for Linux......](https:&#x2F;&#x2F;blog.mjjames.co.uk&#x2F;2019&#x2F;06&#x2F;can-you-use-buildroot-with-windows.html) 
*A quick noteI started this blog post back in August of 2018 and never completed it. Essentially I wrote most of it and then found I just couldn&#39;t run BuildRoot properly, I came back to it every Windows 10 release due to performance improvements etc however its only now with WSL2 that this is possible. Read on to find out the full story :)Original PostI love Windows Subsystem for Linux, I mention it all the time in work, done &quot;brown bag&quot; sessions on it, even did a lightning talk on it at DDDSW 18.This week I&#39;ve been working with a contractor to produce essentially an Embedded OS for a project. Previously I&#39;ve always used existing distributions and made them &quot;lite&quot; or used preconfigured ones, Raspbian Lite for example however he promptly told me I&#39;m doing it wrong and that I shoudl be using BuildRoot.Buildroot is a simple, efficient and easy-to-use tool to generate embedded Linux systems through cross-compilation.Sound&#39;s interesting but what does it do....In essence as I understand it (which could be wrong &#x2F; nieve) it allows you to define a build process that allows you to produce your own flavour of a Linux distribution, meaning it only contains the packages you need. No extra random stuff, you have as small distribution as you need and hopefully far more secure as you haven&#39;t included things you don&#39;t need and could &quot;expose&quot; you.Sounds great. The contractor got on with building us a base OS to get a feel for the system and showed us how we can then pull in our software as packages into the OS. I&#39;m working on a big puse to get our software converted to .Net Core and running on Linux and this is one of the hurdles of making it possible.Today he said, go checkout the git repo on your Ubuntu VM and run the build script..... So I did and was amazed how it &quot;just worked&quot; once I had got the missing dependencies installed...... I didn&#39;t have make installed and apparently this means I&#39;m not a real embedded developer.Great, but I hate having to run VM&#39;s and having to introduce a new Ubuntu or Debian VM for all the other dev&#39;s and even Build Agent into our TFS infrastructure didn&#39;t really feel me with joy.So I threw down a challenge, can&#39;t I just do this without the VM by using Windows Subsytem for Linux??? If I could it wouldn&#39;t be tied down to what ever CPU and memory resource I allocated the VM, it could use *all* of my cores and memory if it wanted.....So I cracked open WSL (i used my Ubuntu one, but Debian etc would work the same) again installed all the dependencies&amp;nbsp;checked out our git repo and then ran the build script......Some long time later....Yup it used *all* of my CPU&#39;s thats my Xeon E5-1620 100%, quad core with hyperthreading at 3.5Ghz is apparently not enough....You can see all of the Linux processes running within Task Manager as well.Some time later still.... The build root process just failed :(. I kept getting intermitent I&#x2F;O related errors and no matter how many times I rebuilt it failed. However it worked fine in a VM. From some reading on the internet WSL does have some I&#x2F;O issues, particulary around git and other applications that are quite intensive.[May 2019]So originally I gave up on this and stuck to my Ubuntu VM. However with the 1903 release of Windows 10 I noted several improvements to WSL so took up the challenge again. This time things appeared to go alot faster,&amp;nbsp; however eventually I hit a new road blocker I gotfakeroot, while creating message channels: Function not implementedThis may be due to a lack of SYSV IPC support.fakeroot: error while starting the &#x60;faked&#39; daemon.Fail. So close yet so far.&amp;nbsp; For now I&#39;m giving up again however at Build 2019 WSL 2 was announced which uses an actual Linux Kernel, this could fix the issue as more kernel calls are implemented etc. I will wait and see.[June 2019]But the story isn&#39;t over yet! Tonight I took the plunge and got the latest Windows 10 Insider Preview and got the all important WSL2! First of all you have to convert your previous distribution to use V2, to do this within a command prompt simply type:wsl --set-version [distributionname] 2&amp;nbsp; &amp;nbsp;Now this process does take some time, it also eats alot of disk space during the process as the image is being translated over, I ran out midway through and got &quot;unspecified error&quot; however once I had tidied up my main disk the conversion ran without a problem.Then came the all important test... I ran my build root script .... .&#x2F;BUILDME.shIt&#39;s worth pointing out that I can no longer see all of the individual Linux processes, I&#39;m told that this is on the backlog and it&#39;d due to WSL 2 now using it&#39;s super small Linux kernel.After not too long...YES!So after almost a year later I can safely say YES you can use Windows Subsystem for Linux to make build root builds!For reference for this blog post I was building Raspberry PI&#39;s Noobs project as my test as it&#39;s sufficently large and a well known entity.This leaves me more excited for the possibility of using WSL in my day to day work life. I use it currently for .Net Core Linux testing but always at some point have to switch to my VM, it now feels once WSL 2 is RTM&#39;d my VM&#39;s days are numbered!*
<!--END_SECTION:feed-->
